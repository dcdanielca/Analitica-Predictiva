{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_learning_resnet50.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jMD1eX-EaL-N","colab_type":"code","outputId":"e28bab92-01a4-43cb-db67-ae6c67068ed6","executionInfo":{"status":"ok","timestamp":1563426407714,"user_tz":300,"elapsed":4162,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lo6S1xOlCWxQ","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Analítica Predictiva/Taller1\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iv9XhxdFg3aN","colab_type":"code","outputId":"bd386c44-b8b0-4257-f65f-c853265119e4","executionInfo":{"status":"ok","timestamp":1563426413707,"user_tz":300,"elapsed":3633,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!ls"],"execution_count":11,"outputs":[{"output_type":"stream","text":["'Arquitectura desde 0.ipynb'\t    transfer_learning_vgg19.ipynb\n"," dataset_office.h5\t\t    usb_prueba.jpg\n"," transfer_learning_resnet50.ipynb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QyB8PIMwGgcN","colab_type":"text"},"source":["En los ejemplos realizados en este cuaderno se utilizaran modelos preentrenados. Estos modelos y las herramenitas para modificarlos se encuentran en las librerias TENSORNETS creadas por Taehoon Lee. Estas se pueden encontrar en el repositorio:\n","https://github.com/taehoonlee/tensornets\n","para instalar estas librerias se requiere cython por lo que se instalan los dos en la siguiente celda"]},{"cell_type":"code","metadata":{"id":"CPytUcG9Cotb","colab_type":"code","outputId":"8500ce19-1fd8-4b93-cdb8-aa66a5cbe810","executionInfo":{"status":"ok","timestamp":1563426421445,"user_tz":300,"elapsed":6387,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!pip install cython\n","!pip install tensornets"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.12)\n","Requirement already satisfied: tensornets in /usr/local/lib/python3.6/dist-packages (0.4.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"92sknewTR4-f","colab_type":"text"},"source":["En el siguiente ejemplo se muestra como cargar una arquitectura pre-entrenada para usarla con un dato nuevo."]},{"cell_type":"code","metadata":{"id":"0AfL_3lrFPNU","colab_type":"code","outputId":"ca6824ac-47f9-4f5b-afb6-fd3732488ac3","executionInfo":{"status":"ok","timestamp":1563426440027,"user_tz":300,"elapsed":15489,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["\n","import tensorflow as tf\n","import tensornets as nets\n","\n","\n","tf.reset_default_graph()\n","\n","inputs = tf.placeholder(tf.float32, [None, 64, 64, 3])\n","model = nets.ResNet50(inputs)\n","assert isinstance(model, tf.Tensor)\n","\n","img = nets.utils.load_img('usb_prueba.jpg', target_size=256, crop_size=64)\n","assert img.shape == (1, 64, 64, 3)\n","\n","with tf.Session() as sess:\n","    img = model.preprocess(img)  # equivalent to img = nets.preprocess(model, img)\n","    sess.run(model.pretrained())  # equivalent to nets.pretrained(model)\n","    preds = sess.run(model, {inputs: img})\n","\n","print(nets.utils.decode_predictions(preds, top=2)[0])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0718 05:07:06.851237 140198867314560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensornets/utils.py:238: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0718 05:07:06.858143 140198867314560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensornets/utils.py:277: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","W0718 05:07:09.490375 140198867314560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensornets/utils.py:246: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0718 05:07:09.491437 140198867314560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensornets/utils.py:125: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/taehoonlee/deep-learning-models/releases/download/resnet/resnet50.h5\n","102899712/102891672 [==============================] - 4s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["W0718 05:07:14.529112 140198867314560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensornets/utils.py:130: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","40960/35363 [==================================] - 0s 0us/step\n","[('n02988304', 'CD_player', 0.82831013), ('n04004767', 'printer', 0.15041754)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J3-QKKHVSUCl","colab_type":"text"},"source":["Pero si lo que queremos es usar una salida intermedia de la arquitectura preentrenada para entrenar el resto con nuestros datos seguimos el siguiente procedimiento usando las funciones  get_middles() y get_outputs():"]},{"cell_type":"code","metadata":{"id":"geUiy_FUSu02","colab_type":"code","outputId":"dbf5f45c-47c7-47cc-b103-ef13cb1caacc","executionInfo":{"status":"ok","timestamp":1563426468589,"user_tz":300,"elapsed":5341,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","import tensornets as nets\n","\n","tf.reset_default_graph()\n","\n","inputs = tf.placeholder(tf.float32, [None, 64, 64, 3])\n","model = nets.ResNet50(inputs)\n","assert isinstance(model, tf.Tensor)\n","\n","img = nets.utils.load_img('usb_prueba.jpg', target_size=256, crop_size=64)\n","assert img.shape == (1, 64, 64, 3)\n","\n","with tf.Session() as sess:\n","    img = model.preprocess(img)\n","    sess.run(model.pretrained())\n","    middles = sess.run(model.get_middles(), {inputs: img})\n","    outputs = sess.run(model.get_outputs(), {inputs: img})\n","    \n","model.print_summary()\n","\n","model.print_middles()\n","assert middles[0].shape == (1, 16, 16, 256)\n","assert middles[-1].shape == (1, 2, 2, 2048)\n","\n","model.print_outputs()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Scope: resnet50\n","Total layers: 54\n","Total weights: 320\n","Total parameters: 25,636,712\n","Scope: resnet50\n","conv2/block1/out:0 (?, 16, 16, 256)\n","conv2/block2/out:0 (?, 16, 16, 256)\n","conv2/block3/out:0 (?, 16, 16, 256)\n","conv3/block1/out:0 (?, 8, 8, 512)\n","conv3/block2/out:0 (?, 8, 8, 512)\n","conv3/block3/out:0 (?, 8, 8, 512)\n","conv3/block4/out:0 (?, 8, 8, 512)\n","conv4/block1/out:0 (?, 4, 4, 1024)\n","conv4/block2/out:0 (?, 4, 4, 1024)\n","conv4/block3/out:0 (?, 4, 4, 1024)\n","conv4/block4/out:0 (?, 4, 4, 1024)\n","conv4/block5/out:0 (?, 4, 4, 1024)\n","conv4/block6/out:0 (?, 4, 4, 1024)\n","conv5/block1/out:0 (?, 2, 2, 2048)\n","conv5/block2/out:0 (?, 2, 2, 2048)\n","conv5/block3/out:0 (?, 2, 2, 2048)\n","Scope: resnet50\n","conv1/pad:0 (?, 70, 70, 3)\n","conv1/conv/BiasAdd:0 (?, 32, 32, 64)\n","conv1/bn/FusedBatchNorm:0 (?, 32, 32, 64)\n","conv1/relu:0 (?, 32, 32, 64)\n","pool1/pad:0 (?, 34, 34, 64)\n","pool1/MaxPool:0 (?, 16, 16, 64)\n","conv2/block1/0/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block1/0/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block1/1/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block1/1/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block1/1/relu:0 (?, 16, 16, 64)\n","conv2/block1/2/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block1/2/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block1/2/relu:0 (?, 16, 16, 64)\n","conv2/block1/3/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block1/3/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block1/out:0 (?, 16, 16, 256)\n","conv2/block2/1/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block2/1/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block2/1/relu:0 (?, 16, 16, 64)\n","conv2/block2/2/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block2/2/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block2/2/relu:0 (?, 16, 16, 64)\n","conv2/block2/3/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block2/3/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block2/out:0 (?, 16, 16, 256)\n","conv2/block3/1/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block3/1/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block3/1/relu:0 (?, 16, 16, 64)\n","conv2/block3/2/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block3/2/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block3/2/relu:0 (?, 16, 16, 64)\n","conv2/block3/3/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block3/3/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block3/out:0 (?, 16, 16, 256)\n","conv3/block1/0/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block1/0/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block1/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block1/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block1/1/relu:0 (?, 8, 8, 128)\n","conv3/block1/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block1/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block1/2/relu:0 (?, 8, 8, 128)\n","conv3/block1/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block1/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block1/out:0 (?, 8, 8, 512)\n","conv3/block2/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block2/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block2/1/relu:0 (?, 8, 8, 128)\n","conv3/block2/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block2/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block2/2/relu:0 (?, 8, 8, 128)\n","conv3/block2/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block2/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block2/out:0 (?, 8, 8, 512)\n","conv3/block3/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block3/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block3/1/relu:0 (?, 8, 8, 128)\n","conv3/block3/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block3/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block3/2/relu:0 (?, 8, 8, 128)\n","conv3/block3/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block3/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block3/out:0 (?, 8, 8, 512)\n","conv3/block4/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block4/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block4/1/relu:0 (?, 8, 8, 128)\n","conv3/block4/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block4/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block4/2/relu:0 (?, 8, 8, 128)\n","conv3/block4/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block4/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block4/out:0 (?, 8, 8, 512)\n","conv4/block1/0/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block1/0/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block1/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block1/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block1/1/relu:0 (?, 4, 4, 256)\n","conv4/block1/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block1/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block1/2/relu:0 (?, 4, 4, 256)\n","conv4/block1/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block1/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block1/out:0 (?, 4, 4, 1024)\n","conv4/block2/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block2/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block2/1/relu:0 (?, 4, 4, 256)\n","conv4/block2/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block2/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block2/2/relu:0 (?, 4, 4, 256)\n","conv4/block2/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block2/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block2/out:0 (?, 4, 4, 1024)\n","conv4/block3/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block3/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block3/1/relu:0 (?, 4, 4, 256)\n","conv4/block3/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block3/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block3/2/relu:0 (?, 4, 4, 256)\n","conv4/block3/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block3/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block3/out:0 (?, 4, 4, 1024)\n","conv4/block4/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block4/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block4/1/relu:0 (?, 4, 4, 256)\n","conv4/block4/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block4/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block4/2/relu:0 (?, 4, 4, 256)\n","conv4/block4/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block4/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block4/out:0 (?, 4, 4, 1024)\n","conv4/block5/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block5/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block5/1/relu:0 (?, 4, 4, 256)\n","conv4/block5/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block5/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block5/2/relu:0 (?, 4, 4, 256)\n","conv4/block5/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block5/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block5/out:0 (?, 4, 4, 1024)\n","conv4/block6/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block6/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block6/1/relu:0 (?, 4, 4, 256)\n","conv4/block6/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block6/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block6/2/relu:0 (?, 4, 4, 256)\n","conv4/block6/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block6/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block6/out:0 (?, 4, 4, 1024)\n","conv5/block1/0/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block1/0/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block1/1/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block1/1/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block1/1/relu:0 (?, 2, 2, 512)\n","conv5/block1/2/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block1/2/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block1/2/relu:0 (?, 2, 2, 512)\n","conv5/block1/3/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block1/3/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block1/out:0 (?, 2, 2, 2048)\n","conv5/block2/1/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block2/1/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block2/1/relu:0 (?, 2, 2, 512)\n","conv5/block2/2/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block2/2/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block2/2/relu:0 (?, 2, 2, 512)\n","conv5/block2/3/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block2/3/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block2/out:0 (?, 2, 2, 2048)\n","conv5/block3/1/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block3/1/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block3/1/relu:0 (?, 2, 2, 512)\n","conv5/block3/2/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block3/2/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block3/2/relu:0 (?, 2, 2, 512)\n","conv5/block3/3/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block3/3/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block3/out:0 (?, 2, 2, 2048)\n","avgpool:0 (?, 2048)\n","logits/BiasAdd:0 (?, 1000)\n","probs:0 (?, 1000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q_O6Dbx2zrCz","colab_type":"text"},"source":["los valores almacenados en middles o en outputs, son salidas en capas intermedias de la arquitectura, y estas salidas se pueden usar como entradas para capas definidas por nosotros. Estas capas puede ser solo el MLP o Full conected al final de la arquitectura..."]},{"cell_type":"code","metadata":{"id":"RTIehYBRGCbI","colab_type":"code","colab":{}},"source":["import h5py\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import tensornets as nets\n","\n","\n","tf.reset_default_graph()\n","\n","# Parámetros para el entrenamiento\n","training_epochs=10\n","batch_size=10  \n","learning_rate = 0.001\n","display_step=1\n","\n","# Parametros de la red neuronal\n","n_hidden_1 = 1024 # 1st layer number of neurons\n","n_hidden_2 = 256 # 2nd layer number of neurons\n","n_input = 2048 # data input (feature shape ?,7,7,2048)\n","n_classes = 7 # total classes (4 signs)\n","\n","X = tf.placeholder(tf.float32, [None, 64, 64, 3])\n","X2 = tf.placeholder(tf.float32, [None, 2, 2, 2048])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","\n","# Para cargar el modelo con la libreria tensornets\n","model = nets.ResNet50(X)\n","assert isinstance(model, tf.Tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GhvEEWy0T0M","colab_type":"code","outputId":"98ec686c-c44f-49d2-dc7b-1dead939ba04","executionInfo":{"status":"ok","timestamp":1563426487625,"user_tz":300,"elapsed":3646,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":456}},"source":["# Leer de una base de datos H5\n","with h5py.File('dataset_office.h5','r') as h5data:\n","    ls=list(h5data.keys())\n","    print(ls)\n","    train_data=np.array(h5data.get('train_img')[:])\n","    train_labels=np.array(h5data.get('train_labels')[:])\n","    test_data=np.array(h5data.get('test_img')[:])\n","    test_labels=np.array(h5data.get('test_labels')[:])\n","\n","print(train_data.shape)    \n","print(train_labels.shape) \n","print(test_data.shape)    \n","print(test_labels.shape)  \n","\n","# Funcion para cambiar de tamaño las imágenes para adpatarlas a la arquitectura\n","def resize_np (np_array):\n","    resized=[]\n","    for i in list(np_array):\n","        larger=cv2.resize(i,(64,64))\n","        resized.append(np.array(larger))\n","    return (np.array(resized).astype(np.float32))\n","\n","# Funcion para cambiar labels a onehot\n","def one_hot_transformation(labels,n_classes):\n","    samples=labels.size\n","    one_hot_labels=np.zeros((samples,n_classes))\n","    for i in range(samples):\n","        one_hot_labels[i,labels[i]]=1\n","    return(one_hot_labels)\n","\n","X_train=resize_np(train_data)\n","print(X_train.shape)\n","X_test=resize_np(test_data)\n","print(X_test.shape)\n","Y_train=one_hot_transformation(train_labels,n_classes)\n","print(Y_train.shape)\n","Y_test=one_hot_transformation(test_labels,n_classes)\n","print(Y_test.shape)\n","\n","# mostrar un ejemplo\n","plt.imshow(X_train[0])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["['test_img', 'test_labels', 'train_img', 'train_labels', 'train_mean', 'val_img', 'val_labels']\n","(6567, 64, 64, 3)\n","(6567,)\n","(2189, 64, 64, 3)\n","(2189,)\n"],"name":"stdout"},{"output_type":"stream","text":["W0718 05:08:06.742901 140198867314560 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["(6567, 64, 64, 3)\n","(2189, 64, 64, 3)\n","(6567, 7)\n","(2189, 7)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f8235236d30>"]},"metadata":{"tags":[]},"execution_count":16},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"REFZ0Rk_SKAq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"88fbbdf8-5f54-49fe-8186-e7967d3d268b","executionInfo":{"status":"ok","timestamp":1563426494574,"user_tz":300,"elapsed":1090,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}}},"source":["# Declaración de los pesos y los bias (weight & bias)\n","weights = {'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],stddev=0.1)),\n","           'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],stddev=0.1)),\n","           'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes],stddev=0.1))\n","          }\n","biases = {'b1': tf.Variable(tf.truncated_normal([n_hidden_1],stddev=0.1)),\n","          'b2': tf.Variable(tf.truncated_normal([n_hidden_2],stddev=0.1)),\n","          'out': tf.Variable(tf.truncated_normal([n_classes],stddev=0.1))\n","         }\n","\n","# Definición del perceptrón multicapa\n","def multilayer_perceptron(x):\n","    pool = tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='VALID')\n","    flat=tf.layers.flatten(pool)\n","    layer_1 = tf.add(tf.matmul(flat, weights['h1']), biases['b1']) # Hidden fully connected layer with 256 neurons\n","    relu_1=tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(relu_1, weights['h2']), biases['b2']) # Hidden fully connected layer with 256 neurons\n","    relu_2=tf.nn.relu(layer_2)\n","    out_layer = tf.matmul(relu_2, weights['out']) + biases['out'] # Output fully connected layer with a neuron for each class\n","    return out_layer\n","# Declarar la operación que aplica el MLP usando la información de entrada\n","logits = multilayer_perceptron(X2)\n","# Declarar las operaciónes que establecen la funcion de perdida y optimización \n","# para el entrenamiento.\n","loss_op = tf.losses.softmax_cross_entropy(\n","    onehot_labels=Y,\n","    logits=logits,\n","    weights=1.0,\n","    scope=None,\n","    loss_collection=tf.GraphKeys.LOSSES,\n","    reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS\n",")\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# Initializing the variables\n","init = tf.global_variables_initializer()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["W0718 05:08:13.706522 140198867314560 deprecation.py:323] From <ipython-input-17-c6d4b9a354c1>:13: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","W0718 05:08:13.959252 140198867314560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"XL33mzkuRDIH","colab_type":"code","outputId":"b34bee43-7032-40d3-f3f8-0eb95850989e","executionInfo":{"status":"ok","timestamp":1563426582238,"user_tz":300,"elapsed":81972,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["with tf.Session() as sess:\n","    sess.run(init)\n","    sess.run(model.pretrained())  # equivalent to nets.pretrained(model)\n","    for epoch in range(training_epochs):\n","        avg_cost = 0.\n","        #obtiene el numero de grupos en que queda dividida la base de datos\n","        total_batch = int(Y_train.shape[0]/batch_size) \n","        # ciclo para entrenar con cada grupo de datos\n","        losses=[]\n","        for i in range(total_batch-1):\n","            batch_x= X_train[i*batch_size:(i+1)*batch_size]\n","            batch_y= Y_train[i*batch_size:(i+1)*batch_size]\n","            features = model.preprocess(batch_x)\n","            features = sess.run(model.get_middles(), {X: features})[-1]\n","            \n","            # Correr la funcion de perdida y la operacion de optimización \n","            # con la respectiva alimentación del placeholder\n","            _,c =sess.run([train_op, loss_op],feed_dict={X2:features,Y:batch_y})\n","            # Promedio de resultados de  = c_api.TF_FinishOperation(op_desc)la funcion de pérdida\n","            losses.append(c)\n","            avg_cost += c / total_batch\n","        # Mostrar el resultado del entrenamiento por grupos\n","        if epoch % display_step == 0:\n","            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n","    print(\"Optimization Finished!\")"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Epoch: 0001 cost=1.835977856\n","Epoch: 0002 cost=0.390559192\n","Epoch: 0003 cost=0.256230953\n","Epoch: 0004 cost=0.185503622\n","Epoch: 0005 cost=0.198758766\n","Epoch: 0006 cost=0.183447627\n","Epoch: 0007 cost=0.159479026\n","Epoch: 0008 cost=0.134025826\n","Epoch: 0009 cost=0.182331880\n","Epoch: 0010 cost=0.131986929\n","Optimization Finished!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y7TroBvAfQ0-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}