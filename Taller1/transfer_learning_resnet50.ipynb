{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_learning_resnet50.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"jMD1eX-EaL-N","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lo6S1xOlCWxQ","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Analítica Predictiva/Taller1\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iv9XhxdFg3aN","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QyB8PIMwGgcN","colab_type":"text"},"source":["En los ejemplos realizados en este cuaderno se utilizaran modelos preentrenados. Estos modelos y las herramenitas para modificarlos se encuentran en las librerias TENSORNETS creadas por Taehoon Lee. Estas se pueden encontrar en el repositorio:\n","https://github.com/taehoonlee/tensornets\n","para instalar estas librerias se requiere cython por lo que se instalan los dos en la siguiente celda"]},{"cell_type":"code","metadata":{"id":"CPytUcG9Cotb","colab_type":"code","colab":{}},"source":["!pip install cython\n","!pip install tensornets"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"92sknewTR4-f","colab_type":"text"},"source":["En el siguiente ejemplo se muestra como cargar una arquitectura pre-entrenada para usarla con un dato nuevo."]},{"cell_type":"code","metadata":{"id":"0AfL_3lrFPNU","colab_type":"code","colab":{}},"source":["\n","import tensorflow as tf\n","import tensornets as nets\n","\n","\n","tf.reset_default_graph()\n","\n","inputs = tf.placeholder(tf.float32, [None, 64, 64, 3])\n","model = nets.ResNet50(inputs)\n","assert isinstance(model, tf.Tensor)\n","\n","img = nets.utils.load_img('usb_prueba.jpg', target_size=256, crop_size=64)\n","assert img.shape == (1, 64, 64, 3)\n","\n","with tf.Session() as sess:\n","    img = model.preprocess(img)  # equivalent to img = nets.preprocess(model, img)\n","    sess.run(model.pretrained())  # equivalent to nets.pretrained(model)\n","    preds = sess.run(model, {inputs: img})\n","\n","print(nets.utils.decode_predictions(preds, top=2)[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J3-QKKHVSUCl","colab_type":"text"},"source":["Pero si lo que queremos es usar una salida intermedia de la arquitectura preentrenada para entrenar el resto con nuestros datos seguimos el siguiente procedimiento usando las funciones  get_middles() y get_outputs():"]},{"cell_type":"code","metadata":{"id":"geUiy_FUSu02","colab_type":"code","outputId":"152b16d1-b926-4eaf-f57e-4615be785179","executionInfo":{"status":"ok","timestamp":1564151294754,"user_tz":300,"elapsed":19952,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import tensorflow as tf\n","import tensornets as nets\n","\n","tf.reset_default_graph()\n","\n","inputs = tf.placeholder(tf.float32, [None, 64, 64, 3])\n","model = nets.ResNet50(inputs)\n","assert isinstance(model, tf.Tensor)\n","\n","img = nets.utils.load_img('usb_prueba.jpg', target_size=256, crop_size=64)\n","assert img.shape == (1, 64, 64, 3)\n","\n","with tf.Session() as sess:\n","    img = model.preprocess(img)\n","    sess.run(model.pretrained())\n","    middles = sess.run(model.get_middles(), {inputs: img})\n","    outputs = sess.run(model.get_outputs(), {inputs: img})\n","    \n","model.print_summary()\n","\n","model.print_middles()\n","assert middles[0].shape == (1, 16, 16, 256)\n","assert middles[-1].shape == (1, 2, 2, 2048)\n","\n","model.print_outputs()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Scope: resnet50\n","Total layers: 54\n","Total weights: 320\n","Total parameters: 25,636,712\n","Scope: resnet50\n","conv2/block1/out:0 (?, 16, 16, 256)\n","conv2/block2/out:0 (?, 16, 16, 256)\n","conv2/block3/out:0 (?, 16, 16, 256)\n","conv3/block1/out:0 (?, 8, 8, 512)\n","conv3/block2/out:0 (?, 8, 8, 512)\n","conv3/block3/out:0 (?, 8, 8, 512)\n","conv3/block4/out:0 (?, 8, 8, 512)\n","conv4/block1/out:0 (?, 4, 4, 1024)\n","conv4/block2/out:0 (?, 4, 4, 1024)\n","conv4/block3/out:0 (?, 4, 4, 1024)\n","conv4/block4/out:0 (?, 4, 4, 1024)\n","conv4/block5/out:0 (?, 4, 4, 1024)\n","conv4/block6/out:0 (?, 4, 4, 1024)\n","conv5/block1/out:0 (?, 2, 2, 2048)\n","conv5/block2/out:0 (?, 2, 2, 2048)\n","conv5/block3/out:0 (?, 2, 2, 2048)\n","Scope: resnet50\n","conv1/pad:0 (?, 70, 70, 3)\n","conv1/conv/BiasAdd:0 (?, 32, 32, 64)\n","conv1/bn/FusedBatchNorm:0 (?, 32, 32, 64)\n","conv1/relu:0 (?, 32, 32, 64)\n","pool1/pad:0 (?, 34, 34, 64)\n","pool1/MaxPool:0 (?, 16, 16, 64)\n","conv2/block1/0/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block1/0/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block1/1/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block1/1/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block1/1/relu:0 (?, 16, 16, 64)\n","conv2/block1/2/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block1/2/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block1/2/relu:0 (?, 16, 16, 64)\n","conv2/block1/3/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block1/3/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block1/out:0 (?, 16, 16, 256)\n","conv2/block2/1/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block2/1/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block2/1/relu:0 (?, 16, 16, 64)\n","conv2/block2/2/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block2/2/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block2/2/relu:0 (?, 16, 16, 64)\n","conv2/block2/3/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block2/3/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block2/out:0 (?, 16, 16, 256)\n","conv2/block3/1/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block3/1/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block3/1/relu:0 (?, 16, 16, 64)\n","conv2/block3/2/conv/BiasAdd:0 (?, 16, 16, 64)\n","conv2/block3/2/bn/FusedBatchNorm:0 (?, 16, 16, 64)\n","conv2/block3/2/relu:0 (?, 16, 16, 64)\n","conv2/block3/3/conv/BiasAdd:0 (?, 16, 16, 256)\n","conv2/block3/3/bn/FusedBatchNorm:0 (?, 16, 16, 256)\n","conv2/block3/out:0 (?, 16, 16, 256)\n","conv3/block1/0/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block1/0/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block1/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block1/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block1/1/relu:0 (?, 8, 8, 128)\n","conv3/block1/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block1/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block1/2/relu:0 (?, 8, 8, 128)\n","conv3/block1/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block1/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block1/out:0 (?, 8, 8, 512)\n","conv3/block2/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block2/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block2/1/relu:0 (?, 8, 8, 128)\n","conv3/block2/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block2/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block2/2/relu:0 (?, 8, 8, 128)\n","conv3/block2/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block2/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block2/out:0 (?, 8, 8, 512)\n","conv3/block3/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block3/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block3/1/relu:0 (?, 8, 8, 128)\n","conv3/block3/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block3/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block3/2/relu:0 (?, 8, 8, 128)\n","conv3/block3/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block3/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block3/out:0 (?, 8, 8, 512)\n","conv3/block4/1/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block4/1/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block4/1/relu:0 (?, 8, 8, 128)\n","conv3/block4/2/conv/BiasAdd:0 (?, 8, 8, 128)\n","conv3/block4/2/bn/FusedBatchNorm:0 (?, 8, 8, 128)\n","conv3/block4/2/relu:0 (?, 8, 8, 128)\n","conv3/block4/3/conv/BiasAdd:0 (?, 8, 8, 512)\n","conv3/block4/3/bn/FusedBatchNorm:0 (?, 8, 8, 512)\n","conv3/block4/out:0 (?, 8, 8, 512)\n","conv4/block1/0/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block1/0/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block1/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block1/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block1/1/relu:0 (?, 4, 4, 256)\n","conv4/block1/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block1/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block1/2/relu:0 (?, 4, 4, 256)\n","conv4/block1/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block1/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block1/out:0 (?, 4, 4, 1024)\n","conv4/block2/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block2/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block2/1/relu:0 (?, 4, 4, 256)\n","conv4/block2/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block2/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block2/2/relu:0 (?, 4, 4, 256)\n","conv4/block2/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block2/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block2/out:0 (?, 4, 4, 1024)\n","conv4/block3/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block3/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block3/1/relu:0 (?, 4, 4, 256)\n","conv4/block3/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block3/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block3/2/relu:0 (?, 4, 4, 256)\n","conv4/block3/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block3/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block3/out:0 (?, 4, 4, 1024)\n","conv4/block4/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block4/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block4/1/relu:0 (?, 4, 4, 256)\n","conv4/block4/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block4/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block4/2/relu:0 (?, 4, 4, 256)\n","conv4/block4/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block4/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block4/out:0 (?, 4, 4, 1024)\n","conv4/block5/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block5/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block5/1/relu:0 (?, 4, 4, 256)\n","conv4/block5/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block5/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block5/2/relu:0 (?, 4, 4, 256)\n","conv4/block5/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block5/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block5/out:0 (?, 4, 4, 1024)\n","conv4/block6/1/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block6/1/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block6/1/relu:0 (?, 4, 4, 256)\n","conv4/block6/2/conv/BiasAdd:0 (?, 4, 4, 256)\n","conv4/block6/2/bn/FusedBatchNorm:0 (?, 4, 4, 256)\n","conv4/block6/2/relu:0 (?, 4, 4, 256)\n","conv4/block6/3/conv/BiasAdd:0 (?, 4, 4, 1024)\n","conv4/block6/3/bn/FusedBatchNorm:0 (?, 4, 4, 1024)\n","conv4/block6/out:0 (?, 4, 4, 1024)\n","conv5/block1/0/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block1/0/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block1/1/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block1/1/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block1/1/relu:0 (?, 2, 2, 512)\n","conv5/block1/2/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block1/2/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block1/2/relu:0 (?, 2, 2, 512)\n","conv5/block1/3/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block1/3/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block1/out:0 (?, 2, 2, 2048)\n","conv5/block2/1/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block2/1/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block2/1/relu:0 (?, 2, 2, 512)\n","conv5/block2/2/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block2/2/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block2/2/relu:0 (?, 2, 2, 512)\n","conv5/block2/3/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block2/3/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block2/out:0 (?, 2, 2, 2048)\n","conv5/block3/1/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block3/1/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block3/1/relu:0 (?, 2, 2, 512)\n","conv5/block3/2/conv/BiasAdd:0 (?, 2, 2, 512)\n","conv5/block3/2/bn/FusedBatchNorm:0 (?, 2, 2, 512)\n","conv5/block3/2/relu:0 (?, 2, 2, 512)\n","conv5/block3/3/conv/BiasAdd:0 (?, 2, 2, 2048)\n","conv5/block3/3/bn/FusedBatchNorm:0 (?, 2, 2, 2048)\n","conv5/block3/out:0 (?, 2, 2, 2048)\n","avgpool:0 (?, 2048)\n","logits/BiasAdd:0 (?, 1000)\n","probs:0 (?, 1000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q_O6Dbx2zrCz","colab_type":"text"},"source":["los valores almacenados en middles o en outputs, son salidas en capas intermedias de la arquitectura, y estas salidas se pueden usar como entradas para capas definidas por nosotros. Estas capas puede ser solo el MLP o Full conected al final de la arquitectura..."]},{"cell_type":"code","metadata":{"id":"RTIehYBRGCbI","colab_type":"code","colab":{}},"source":["import h5py\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import tensornets as nets\n","\n","\n","tf.reset_default_graph()\n","\n","# Parámetros para el entrenamiento\n","training_epochs=20\n","batch_size=10  \n","learning_rate = 0.001\n","display_step=1\n","\n","# Parametros de la red neuronal\n","n_hidden_1 = 1024 # 1st layer number of neurons\n","n_hidden_2 = 256 # 2nd layer number of neurons\n","n_input = 2048 # data input (feature shape ?,7,7,2048)\n","n_classes = 17 # total classes (4 signs)\n","\n","X = tf.placeholder(tf.float32, [None, 64, 64, 3])\n","X2 = tf.placeholder(tf.float32, [None, 2, 2, 2048])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","\n","# Para cargar el modelo con la libreria tensornets\n","model = nets.ResNet50(X)\n","assert isinstance(model, tf.Tensor)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6GhvEEWy0T0M","colab_type":"code","outputId":"0512533a-2030-4eb5-ae50-c1811f731af1","executionInfo":{"status":"ok","timestamp":1564151298594,"user_tz":300,"elapsed":23770,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":484}},"source":["# Leer de una base de datos H5\n","with h5py.File('datasetCosas.h5','r') as h5data:\n","    ls=list(h5data.keys())\n","    print(ls)\n","    train_data=np.array(h5data.get('train_img')[:])\n","    train_labels=np.array(h5data.get('train_labels')[:])\n","    test_data=np.array(h5data.get('test_img')[:])\n","    test_labels=np.array(h5data.get('test_labels')[:])\n","\n","print(train_data.shape)    \n","print(train_labels.shape) \n","print(test_data.shape)    \n","print(test_labels.shape)  \n","\n","# Funcion para cambiar de tamaño las imágenes para adpatarlas a la arquitectura\n","def resize_np (np_array):\n","    resized=[]\n","    for i in list(np_array):\n","        larger=cv2.resize(i,(64,64))\n","        resized.append(np.array(larger))\n","    return (np.array(resized).astype(np.float32))\n","\n","# Funcion para cambiar labels a onehot\n","def one_hot_transformation(labels,n_classes):\n","    samples=labels.size\n","    one_hot_labels=np.zeros((samples,n_classes))\n","    for i in range(samples):\n","        one_hot_labels[i,labels[i]]=1\n","    return(one_hot_labels)\n","\n","X_train=resize_np(train_data)\n","print(X_train.shape)\n","X_test=resize_np(test_data)\n","print(X_test.shape)\n","Y_train=one_hot_transformation(train_labels,n_classes)\n","print(Y_train.shape)\n","Y_test=one_hot_transformation(test_labels,n_classes)\n","print(Y_test.shape)\n","\n","# mostrar un ejemplo\n","plt.imshow(X_train[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['list_classes', 'test_img', 'test_labels', 'train_img', 'train_labels']\n","(20360, 64, 64, 3)\n","(20360,)\n","(5091, 64, 64, 3)\n","(5091,)\n"],"name":"stdout"},{"output_type":"stream","text":["W0726 14:28:18.242051 140178417211264 image.py:648] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["(20360, 64, 64, 3)\n","(5091, 64, 64, 3)\n","(20360, 17)\n","(5091, 17)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f7b91469b00>"]},"metadata":{"tags":[]},"execution_count":81},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"REFZ0Rk_SKAq","colab_type":"code","colab":{}},"source":["# Declaración de los pesos y los bias (weight & bias)\n","weights = {'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],stddev=0.1)),\n","           'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],stddev=0.1)),\n","           'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes],stddev=0.1))\n","          }\n","biases = {'b1': tf.Variable(tf.truncated_normal([n_hidden_1],stddev=0.1)),\n","          'b2': tf.Variable(tf.truncated_normal([n_hidden_2],stddev=0.1)),\n","          'out': tf.Variable(tf.truncated_normal([n_classes],stddev=0.1))\n","         }\n","\n","# Definición del perceptrón multicapa\n","def multilayer_perceptron(x):\n","    pool = tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='VALID')\n","    flat=tf.layers.flatten(pool)\n","    layer_1 = tf.add(tf.matmul(flat, weights['h1']), biases['b1']) # Hidden fully connected layer with 256 neurons\n","    relu_1=tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(relu_1, weights['h2']), biases['b2']) # Hidden fully connected layer with 256 neurons\n","    relu_2=tf.nn.relu(layer_2)\n","    out_layer = tf.matmul(relu_2, weights['out']) + biases['out'] # Output fully connected layer with a neuron for each class\n","    return out_layer\n","# Declarar la operación que aplica el MLP usando la información de entrada\n","logits = multilayer_perceptron(X2)\n","# Declarar las operaciónes que establecen la funcion de perdida y optimización \n","# para el entrenamiento.\n","loss_op = tf.losses.softmax_cross_entropy(\n","    onehot_labels=Y,\n","    logits=logits,\n","    weights=1.0,\n","    scope=None,\n","    loss_collection=tf.GraphKeys.LOSSES,\n","    reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS\n",")\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# Initializing the variables\n","init = tf.global_variables_initializer()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XL33mzkuRDIH","colab_type":"code","outputId":"c9af5140-8821-4db4-a301-10dd0036e512","executionInfo":{"status":"ok","timestamp":1564151831566,"user_tz":300,"elapsed":556720,"user":{"displayName":"Daniel Alexander Cano Cuartas","photoUrl":"https://lh5.googleusercontent.com/-4fBWDm-PEGk/AAAAAAAAAAI/AAAAAAAABLI/KrZmtZcFWbs/s64/photo.jpg","userId":"08439480702110199597"}},"colab":{"base_uri":"https://localhost:8080/","height":426}},"source":["with tf.Session() as sess:\n","    sess.run(init)\n","    sess.run(model.pretrained())  # equivalent to nets.pretrained(model)\n","    for epoch in range(training_epochs):\n","        avg_cost = 0.\n","        #obtiene el numero de grupos en que queda dividida la base de datos\n","        total_batch = int(Y_train.shape[0]/batch_size) \n","        # ciclo para entrenar con cada grupo de datos\n","        losses=[]\n","        for i in range(total_batch-1):\n","            batch_x= X_train[i*batch_size:(i+1)*batch_size]\n","            batch_y= Y_train[i*batch_size:(i+1)*batch_size]\n","            features = model.preprocess(batch_x)\n","            features = sess.run(model.get_middles(), {X: features})[-1]\n","            \n","            # Correr la funcion de perdida y la operacion de optimización \n","            # con la respectiva alimentación del placeholder\n","            _,c =sess.run([train_op, loss_op],feed_dict={X2:features,Y:batch_y})\n","            # Promedio de resultados de  = c_api.TF_FinishOperation(op_desc)la funcion de pérdida\n","            losses.append(c)\n","            avg_cost += c / total_batch\n","        # Mostrar el resultado del entrenamiento por grupos\n","        if epoch % display_step == 0:\n","            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n","    print(\"Optimization Finished!\")\n","    \n","    predict_op = tf.nn.softmax(logits)  # Apply softmax to logits\n","    correct_prediction = tf.equal(tf.argmax(predict_op, 1), tf.argmax(Y, 1)) \n","\n","    # Calcular la predicción sobre el conjunto de test \n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","    \n","    train_accuracy = []\n","    for i in range(total_batch-1):\n","      batch_x= X_train[i*batch_size:(i+1)*batch_size]\n","      batch_y= Y_train[i*batch_size:(i+1)*batch_size]\n","      features = model.preprocess(batch_x)\n","      features = sess.run(model.get_middles(), {X: features})[-1]\n","      train_accuracy.append(accuracy.eval({X2: features, Y: batch_y}))\n","    print(\"Train Accuracy:\", sum(train_accuracy)/total_batch)\n","    \n","    test_accuracy = []\n","    for i in range(int(Y_test.shape[0]/batch_size)-1):\n","      batch_x= X_test[i*batch_size:(i+1)*batch_size]\n","      batch_y= Y_test[i*batch_size:(i+1)*batch_size]\n","      features = model.preprocess(batch_x)\n","      features = sess.run(model.get_middles(), {X: features})[-1]\n","      test_accuracy.append(accuracy.eval({X2: features, Y: batch_y}))\n","    print(\"Test Accuracy:\", sum(test_accuracy)/int(Y_test.shape[0]/batch_size))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 0001 cost=1.651926813\n","Epoch: 0002 cost=0.804281904\n","Epoch: 0003 cost=0.638585441\n","Epoch: 0004 cost=0.510294811\n","Epoch: 0005 cost=0.438384619\n","Epoch: 0006 cost=0.353689888\n","Epoch: 0007 cost=0.327079769\n","Epoch: 0008 cost=0.277006632\n","Epoch: 0009 cost=0.250365266\n","Epoch: 0010 cost=0.233811622\n","Epoch: 0011 cost=0.216175999\n","Epoch: 0012 cost=0.204989036\n","Epoch: 0013 cost=0.203918306\n","Epoch: 0014 cost=0.184365259\n","Epoch: 0015 cost=0.175817144\n","Epoch: 0016 cost=0.176123129\n","Epoch: 0017 cost=0.169819494\n","Epoch: 0018 cost=0.157454330\n","Epoch: 0019 cost=0.165021369\n","Epoch: 0020 cost=0.148987685\n","Optimization Finished!\n","Train Accuracy: 0.9613948861074822\n","Test Accuracy: 0.7848722956386671\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mlvSTo_hrhv3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}